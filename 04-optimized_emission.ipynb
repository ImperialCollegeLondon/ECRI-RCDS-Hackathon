{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "526290a5",
   "metadata": {},
   "source": [
    "### Find the top *k* features most correlated to Saleprice (Optimized method)\n",
    "(House price data train.csv from https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1a6427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import psutil\n",
    "import os, gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from codecarbon import OfflineEmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f986c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # Memory in MB\n",
    "\n",
    "def optimized_feature_selection(X, y, k=20):\n",
    "    #print(f\"Memory before optimized selection: {get_memory_usage():.2f} MB\")\n",
    "    #start_time = time.time()\n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    # use corrwith to reduce runtime\n",
    "    correlations = np.abs(X_numeric.corrwith(y))\n",
    "    # use fillna to reduce runtime of checking with isnan in loops\n",
    "    correlations = correlations.fillna(0)\n",
    "    #top_k_features = correlations.nlargest(k).index.tolist() #this may use more time\n",
    "    #instead of the above line, use the following two lines instead\n",
    "    top_k_indices = np.argsort(correlations)[-k:]\n",
    "    selected_features = X_numeric.columns[top_k_indices].tolist()\n",
    "    #print(f\"Memory after optimized selection: {get_memory_usage():.2f} MB\")\n",
    "    #print(f\"Optimized feature selection took {time.time() - start_time} seconds\")\n",
    "    return selected_features\n",
    "\n",
    "def load_and_evaluate(file_path, k=20, n_runs = 100):\n",
    "    # Initialize lists to store metrics\n",
    "    memory_before_list = []\n",
    "    memory_after_list = []\n",
    "    memory_increase_list = []\n",
    "    runtime_list = []\n",
    "    mse_list = []\n",
    "    emissions_list = []\n",
    "\n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=['SalePrice', 'Id'])\n",
    "    y = data['SalePrice']\n",
    "\n",
    "    X = data.drop(columns=['SalePrice', 'Id'])\n",
    "    y = data['SalePrice']\n",
    "    # Handle missing values for numerical columns \n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    X_categorical = X.select_dtypes(exclude=[np.number])\n",
    "    # Combine numerical and categorical columns\n",
    "    X = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "    \n",
    "   \n",
    "    if X.isna().any().any():\n",
    "        X = X.fillna(0)  # Fill any remaining NaNs with 0 (e.g., for edge cases)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # Monte Carlo method for testing mem use and runtime\n",
    "    print(f\"Running naive method {n_runs} times...\")\n",
    "    # Calling psutil.cpu_precent() for 1 seconds\n",
    "    cpu_use_start = psutil.cpu_percent(1)\n",
    "\n",
    "    #tracker = EmissionsTracker(project_name=\"naive_feature_selection\", output_file=\"naive_emissions.csv\")\n",
    "    tracker = OfflineEmissionsTracker(\n",
    "        project_name=\"optimised_feature_selection\",\n",
    "        output_file=\"optimised_emissions.csv\",\n",
    "        country_iso_code=\"GBR\",\n",
    "        log_level=\"warning\"\n",
    "    )\n",
    "    #tracker = OfflineEmissionsTracker(country_iso_code=\"UK\")\n",
    "    tracker.start()\n",
    "    for run in range(n_runs):\n",
    "        gc.collect() # clear memory before each run\n",
    "        mem_use_before = get_memory_usage()\n",
    "        start_time = time.time()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+run)\n",
    "\n",
    "        selected_features = optimized_feature_selection(X_train, y_train, k)\n",
    "        model = LinearRegression()\n",
    "        \n",
    "        X_train_selected = X_train[selected_features]\n",
    "        X_test_selected = X_test[selected_features]\n",
    "        \n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "        mem_use_after = get_memory_usage()\n",
    "        end_time = time.time()\n",
    "        # Store metrics\n",
    "        memory_before_list.append(mem_use_before)\n",
    "        memory_after_list.append(mem_use_after)\n",
    "        memory_increase_list.append(mem_use_after - mem_use_before)\n",
    "        runtime_list.append(end_time - start_time)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "    emissions = tracker.stop()  # Emissions in kg COâ‚‚eq\n",
    "    cpu_use_end = psutil.cpu_percent(1)\n",
    "    scaled_emissions = emissions * (cpu_use_end - cpu_use_start) / 100\n",
    "    emissions_list.append(scaled_emissions)\n",
    "    #model = LinearRegression()\n",
    "    #X_train_selected = X_train[selected_features].toarray() if sp.issparse(X_train) else X_train[selected_features]\n",
    "    #X_test_selected = X_test[selected_features].toarray() if sp.issparse(X_test) else X_test[selected_features]\n",
    "    #X_train_selected = X_train[selected_features].toarray() if sp.issparse(X_train) else X_train[selected_features]\n",
    "    #X_test_selected = X_test[selected_features].toarray() if sp.issparse(X_test) else X_test[selected_features]\n",
    "    #if np.any(np.isnan(X_train_selected)):\n",
    "    #    raise ValueError(\"NaNs detected in X_train_selected\")\n",
    "    #model.fit(X_train_selected, y_train)\n",
    "    #y_pred = model.predict(X_test_selected)\n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    #print(f\"Mean Squared Error with {k} features: {mse}\")\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'memory_before_mean (MB)': np.mean(memory_before_list),\n",
    "        'memory_before_std': np.std(memory_before_list),\n",
    "        'memory_after_mean (MB)': np.mean(memory_after_list),\n",
    "        'memory_after_std': np.std(memory_after_list),\n",
    "        'memory_increase_mean (MB)': np.mean(memory_increase_list),\n",
    "        'memory_increase_std': np.std(memory_increase_list),\n",
    "        'runtime_mean (Seconds)': np.mean(runtime_list),\n",
    "        'runtime_std': np.std(runtime_list),\n",
    "        'MSE_mean': np.mean(mse_list),\n",
    "        'MSE_std': np.std(mse_list),\n",
    "        'emissions_total (kg CO2eq)': np.sum(emissions_list)\n",
    "    }\n",
    "    \n",
    "    return selected_features, mse, stats\n",
    "\n",
    "def generate_report(stats, method=\"Optimized\"):\n",
    "    report = f\"# {method} Method Statistical Report\\n\\n\"\n",
    "    report += \"## Summary Statistics\\n\\n\"\n",
    "    report += \"| Metric | Mean | Standard Deviation |\\n\"\n",
    "    report += \"|--------|------|--------------------|\\n\"\n",
    "    report += f\"| Memory Before (MB) | {stats['memory_before_mean (MB)']:.2f} | {stats['memory_before_std']:.2f} |\\n\"\n",
    "    report += f\"| Memory After (MB) | {stats['memory_after_mean (MB)']:.2f} | {stats['memory_after_std']:.2f} |\\n\"\n",
    "    report += f\"| Memory Increase (MB) | {stats['memory_increase_mean (MB)']:.2f} | {stats['memory_increase_std']:.2f} |\\n\"\n",
    "    report += f\"| Runtime (seconds) | {stats['runtime_mean (Seconds)']:.6f} | {stats['runtime_std']:.6f} |\\n\"\n",
    "    report += f\"| MSE | {stats['MSE_mean']:.2f} | {stats['MSE_std']:.2f} |\\n\"\n",
    "    report += f\"\\n## Environmental Impact\\n\"\n",
    "    report += f\"- Total Emissions (kg CO2eq): {stats['emissions_total (kg CO2eq)']:.6f}\\n\"\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a1b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive method 500 times...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:15:08] offline tracker init\n",
      "[codecarbon WARNING @ 17:15:08] Multiple instances of codecarbon are allowed to run at the same time.\n",
      "[codecarbon WARNING @ 17:15:08] Error while trying to count physical CPUs: [Errno 2] No such file or directory: 'lscpu'. Defaulting to 1.\n",
      "[codecarbon WARNING @ 17:15:09] We saw that you have a Apple M4 but we don't know it. Please contact us.\n",
      "[codecarbon WARNING @ 17:15:15] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Mac OS detected: Please install Intel Power Gadget or enable PowerMetrics sudo to measure CPU\n",
      "\n",
      "[codecarbon WARNING @ 17:15:15] No CPU tracking mode found. Falling back on CPU constant mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features (last run): ['LotArea', 'HalfBath', '2ndFlrSF', 'WoodDeckSF', 'LotFrontage', 'OpenPorchSF', 'BsmtFinSF1', 'Fireplaces', 'MasVnrArea', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt', 'TotRmsAbvGrd', 'FullBath', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual']\n",
      "Optimized method report generated: optimized_stats_report.md\n",
      "\n",
      "Summary Statistics:\n",
      "memory_before_mean (MB): 185.325391\n",
      "memory_before_std: 1.501888\n",
      "memory_after_mean (MB): 185.371289\n",
      "memory_after_std: 1.327574\n",
      "memory_increase_mean (MB): 0.045898\n",
      "memory_increase_std: 0.267205\n",
      "runtime_mean (Seconds): 0.015336\n",
      "runtime_std: 0.004588\n",
      "MSE_mean: 1495907264.707669\n",
      "MSE_std: 668916768.381671\n",
      "emissions_total (kg CO2eq): 0.000008\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    file_path = \"data/train.csv\"\n",
    "    n_runs = 500\n",
    "    selected_features, mse, stats = load_and_evaluate(file_path,  k=20, n_runs=n_runs )\n",
    "    print(f\"Selected features (last run): {selected_features}\")\n",
    "    report = generate_report(stats, method=\"Optimized\")\n",
    "    with open(\"optimized_stats_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(\"Optimized method report generated: optimized_stats_report.md\")\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
