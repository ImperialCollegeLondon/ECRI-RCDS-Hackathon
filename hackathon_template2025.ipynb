{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b54f3a28",
   "metadata": {},
   "source": [
    "# Hack! Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26971b8",
   "metadata": {},
   "source": [
    "Please use this template to code.\n",
    "\n",
    "- Remove libraries and some lines as necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f463f",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import psutil, time, os, gc, statistics, warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from memory_profiler import memory_usage\n",
    "from codecarbon import EmissionsTracker\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4c07f",
   "metadata": {},
   "source": [
    "### Functions for normalization and tracking memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50059d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get memory usage\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 / 1024  # Memory in MB\n",
    "\n",
    "# Function to normalize metrics\n",
    "def normalize_metric(values, maximize=True):\n",
    "    if not values:\n",
    "        return [1.0] * len(values)\n",
    "    min_val = min(values)\n",
    "    max_val = max(values)\n",
    "    if max_val == min_val:\n",
    "        return [1.0] * len(values)\n",
    "    if maximize:\n",
    "        return [(x - min_val) / (max_val - min_val) for x in values]\n",
    "    return [(max_val - x) / (max_val - min_val) for x in values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92eed43",
   "metadata": {},
   "source": [
    "### Function plotting the ML output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22eed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Students, implement the plot_validation_curve function\n",
    "# Instructions: This function should create a validation curve plot for a given estimator.\n",
    "# - Use validation_curve to compute training and test scores for different parameter values\n",
    "# - Plot mean training and test scores with standard deviation as shaded areas\n",
    "# - Ensure the plot is properly labeled with title, x-axis, y-axis, legend, and grid\n",
    "# - Handle None values in param_range by converting them to a large integer (e.g., 100) for plotting\n",
    "def plot_validation_curve(estimator, X, y, param_name, param_range, cv=5, title=\"Validation Curve\"):\n",
    "    # Replace this with your implementation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83687c48",
   "metadata": {},
   "source": [
    "### Functions for iterating ML functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be5a82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run analysis with multiple iterations\n",
    "def run_analysis_with_repeats(data_dir, num_runs=1):\n",
    "    results = []\n",
    "    data_rows = None\n",
    "    data_targets = None\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        gc.collect()  # Clear memory before each run\n",
    "        result, rows, targets = analyze_ml_models(data_dir)\n",
    "        results.append(result)\n",
    "        data_rows = rows\n",
    "        data_targets = targets\n",
    "    \n",
    "    # Aggregate metrics dynamically\n",
    "    aggregated_results = []\n",
    "    for method in ['LR', 'RF', 'DT']: # Replace with actual method names used in results\n",
    "        metrics = {\n",
    "            \"Method\": method,\n",
    "            \"Accuracy\": statistics.mean([r[f\"{method} Accuracy\"] for r in results]),\n",
    "            \"Train Time (s)\": statistics.mean([r[f\"{method} Train Time (s)\"] for r in results]),\n",
    "            \"Pred Time (s)\": statistics.mean([r[f\"{method} Pred Time (s)\"] for r in results]),\n",
    "            \"Memory (MB)\": statistics.mean([r[f\"{method} Memory (MB)\"] for r in results]),\n",
    "            \"Emissions (kg CO2eq)\": statistics.mean([r[f\"{method} Emissions (kg CO2eq)\"] for r in results]),\n",
    "            \"Composite Score\": statistics.mean([r[f\"{method} Composite Score\"] for r in results])\n",
    "        }\n",
    "        aggregated_results.append(metrics)\n",
    "    \n",
    "    return aggregated_results, (pd.DataFrame(data_rows), pd.Series(data_targets))\n",
    "\n",
    "# TODO: Students, implement the analyze_ml_models function\n",
    "# Instructions: This function processes graph data, trains ML models, and evaluates them\n",
    "# Steps:\n",
    "# 1. Read graph files from data_dir using networkx, compute onion layers, and create features\n",
    "# 2. Preprocess data: convert to DataFrame, handle missing/non-finite values, scale features\n",
    "# 3. Split data into training and test sets (50% split, random_state=33)\n",
    "# 4. Define models (LogisticRegression, RandomForestClassifier, DecisionTreeClassifier) with GridSearchCV\n",
    "# 5. Train models, measure training/prediction time, memory usage, and emissions using EmissionsTracker\n",
    "# 6. Compute accuracy, confusion matrix, and classification report for each model\n",
    "# 7. Normalize metrics and compute composite score using weights\n",
    "# 8. Return results dictionary, feature DataFrame, and targets\n",
    "def analyze_ml_models(data_dir):\n",
    "    rows = []\n",
    "    targets = []\n",
    "    \n",
    "    # Step 1: Read and process graph data\n",
    "    # Hint: Use nx.read_adjlist and nx.onion_layers\n",
    "    # Create a feature vector for each graph based on layer sizes (1 to 100)\n",
    "    \n",
    "    # Step 2: Preprocess data\n",
    "    # Hint: Create DataFrame, handle missing/non-finite values, use StandardScaler\n",
    "    \n",
    "    # Step 3: Split data\n",
    "    # Hint: Use train_test_split with train_size=0.5, random_state=33\n",
    "    \n",
    "    # Step 4: Define models and parameter grids\n",
    "    models = [\n",
    "        # Define LogisticRegression with param_grid for 'C'\n",
    "        # Define RandomForestClassifier with param_grid for 'n_estimators', 'max_depth', 'min_samples_split'\n",
    "        # Define DecisionTreeClassifier with param_grid for 'max_depth', 'min_samples_split'\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    raw_metrics = { 'accuracy': [], 'train_time': [], 'pred_time': [], 'memory': [], 'emissions': [] }\n",
    "    \n",
    "    # Step 5-7: Train, evaluate, and compute metrics for each model\n",
    "    # Hint: Use GridSearchCV, memory_usage, EmissionsTracker, accuracy_score, etc.\n",
    "    \n",
    "    # Step 8: Return results\n",
    "    return results, rows, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af86260",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818da9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = \"data\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: {data_dir} directory not found.\")\n",
    "        return\n",
    "    \n",
    "    num_runs = 5  # Set to 1 for single run as in original code\n",
    "    ml_metrics, (X, y) = run_analysis_with_repeats(data_dir, num_runs)\n",
    "    \n",
    "    print(\"\\nTable: Machine Learning Performance Comparison\")\n",
    "    ml_df = pd.DataFrame(ml_metrics)\n",
    "    print(ml_df.round(6))\n",
    "    ml_df.to_csv(\"ml_analysis_comparison.csv\", index=False)\n",
    "    print(\"\\nMachine learning results saved to ml_analysis_comparison.csv\")\n",
    "    \n",
    "    # TODO: Validation curves\n",
    "    # modify the following code to plot validation curves for each model used in the analysis\n",
    "    lr = LogisticRegression(class_weight='balanced')\n",
    "    plot_validation_curve(lr, X, y, param_name='C', param_range=[0.01, 0.1, 1, 10, 100], title=\"Validation Curve for Logistic Regression\")\n",
    "    \n",
    "    rf = RandomForestClassifier(class_weight='balanced', random_state=33)\n",
    "    plot_validation_curve(rf, X, y, param_name='max_depth', param_range=[None, 5, 10, 15, 20], title=\"Validation Curve for Random Forest (max_depth)\")\n",
    "    \n",
    "    dt = DecisionTreeClassifier(class_weight='balanced', random_state=33)\n",
    "    plot_validation_curve(dt, X, y, param_name='max_depth', param_range=[None, 5, 10, 15, 20], title=\"Validation Curve for Decision Tree (max_depth)\")\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
