{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606ce95e",
   "metadata": {},
   "source": [
    " # Hackathon task: classifying graphs\n",
    "\n",
    "There are a number of simple recipes for creating random graphs, known as [graph generators](https://networkx.org/documentation/stable/reference/generators.html).\n",
    "\n",
    "The properties of graphs created using different recipes are somewhat distinctive, so in principle we can use machine learning to predict the source generator for a given graph.\n",
    "\n",
    "You are given a sample training dataset (in `data/train`) containing graphs created using five different generators. The number of vertices and the other generator parameters may be different between individual graphs.\n",
    "\n",
    "These graphs are provided in the [adjacency list](https://networkx.org/documentation/stable/reference/readwrite/adjlist.html) format.\n",
    "\n",
    "Your task is to produce a classifier that has\n",
    "- high accuracy in distinguishing between these five generators, and\n",
    "- low total CO<sub>2</sub> emissions (considering the three stages of model development, training and testing).\n",
    "\n",
    "You are free to use any approach and any third-party packages/resources you choose, in any programming language. \n",
    "\n",
    "Probably if using python you will want to use the [scikit-learn](https://scikit-learn.org/stable/) package to create your classifier.\n",
    "\n",
    "One important decision will be how to extract informative features from the graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f1ce44",
   "metadata": {},
   "source": [
    " ## One possible approach\n",
    "\n",
    "Given a <a href=\"https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)\">graph</a> G, we can apply the following procedure:\n",
    "\n",
    "1) remove all vertices with degree 0 (i.e. unconnected vertices)\n",
    "2) remove all vertices with degree 1 (i.e. those connected to only one other vertex)\n",
    "3) keep repeating (2) until there are no more vertices with degree 1\n",
    "4) output the resulting graph, known as the <a href=\"https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)\">2-core</a> of the original graph G.\n",
    "\n",
    "We can continue the procedure with progressively higher degrees to generate the 3-core, 4-core etc...\n",
    "\n",
    "The [onion decomposition](https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.core.onion_layers.html#networkx.algorithms.core.onion_layers) of a graph G is based on the k-core algorithm explained earlier, but records the vertices removed in each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8294be8",
   "metadata": {},
   "source": [
    "\n",
    "### Example: onion decomposition of the Facebook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd83917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# load a graph\n",
    "G = nx.read_adjlist(\"data/facebook.txt\", nodetype=int)\n",
    "\n",
    "print(f\"original graph has {len(G.nodes):d} vertices and {len(G.edges):d} edges\")\n",
    "\n",
    "od = nx.onion_layers(G)\n",
    "\n",
    "for i in range(1, 21):\n",
    "    layer_i = [v for v in od.keys() if od[v] == i]\n",
    "    print(f\"layer {i:d} contains {len(layer_i):d} vertices\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbb7fc",
   "metadata": {},
   "source": [
    "The sequence of layer sizes contains a lot of information about the local structure of the graph. \n",
    "\n",
    "It might make a useful set of features for distinguishing between graphs of different types..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adda2c",
   "metadata": {},
   "source": [
    "## Tracking emissions\n",
    "\n",
    "Please use the CodeCarbon tracker to estimate the total CO~2~ emissions produced during the development of your model.\n",
    "\n",
    "If working in a notebook, an easy way to do this is to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59370369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28f12f",
   "metadata": {},
   "source": [
    "once at the beginning of your coding, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fe7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions = tracker.stop()\n",
    "print(emissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25dda05",
   "metadata": {},
   "source": [
    "when you are ready to do the final model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402d61d",
   "metadata": {},
   "source": [
    "## A note on the use of GenAI\n",
    "\n",
    "You may want to make use of Generative AI to help you with your coding.\n",
    "This is perfectly acceptable, but there is an associated environmental cost that we will need to take into account.\n",
    "\n",
    "It is currently difficult to accurately estimate the emissions associated with tools such as GitHub Copilot (although there are some projects that are aiming towards similar functionality as CodeCarbon for LLM APIs, e.g. https://ecologits.ai/).\n",
    "\n",
    "However, we do have [some general estimates](https://piktochart.com/blog/carbon-footprint-of-chatgpt/) for the CO2 emissions that can be assigned to a single LLM query.\n",
    "\n",
    "If you want to use GenAI for this hackathon task, please keep a record of the approximate number of queries you make to GenAI tools during your coding. You will be asked to enter this number when you submit your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca24db",
   "metadata": {},
   "source": [
    "## Results submission\n",
    "\n",
    "Towards the end of the hackathon time, we will provide a link to the final evaluation dataset, which will be a zipped directory `test.zip`.\n",
    "\n",
    "Train your final model using the full `train` dataset and record the associated CO<sub>2</sub> emissions.\n",
    "\n",
    "Use your model to predict the generator of each graph in the `test` dataset and record the associated CO<sub>2</sub> emissions.\n",
    "\n",
    "Calculate the overall accuracy of your model predictions on this dataset, as a decimal.\n",
    "\n",
    "(Each of the five graph generators has the same number of test graphs, so the expected accuracy of a random predictor is `0.2`.)\n",
    "\n",
    "Submit your results using [this form](https://forms.office.com/e/2FgQFkth4L).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515b1e02",
   "metadata": {},
   "source": [
    "## Competition Scoring\n",
    "\n",
    "This competition will have a winner. We will rank all entries according to their accuracy and CO<sub>2</sub> emissions. For each entry, we will sum your rank according to each of these two criteria, and the entry with the lowest total rank will be declared the winner.\n",
    "\n",
    "For determining the CO<sub>2</sub> emissions, we will use the following formula:\n",
    "\n",
    "$$\n",
    "\\text{total emissions (kg CO₂)} = 0.004(\\text{kg CO₂}) * \\text{number of GenAI queries} + \\\\\n",
    "\\text{emissions from model development (kg CO₂)} +  \\\\\n",
    "10,000 (\\text{emissions from model training (kg CO₂)} + \\text{emissions from model testing (kg CO₂)}) \n",
    "$$\n",
    "\n",
    "The factor of 10,000 is to account for the fact that the problem is short and small, and only repeated once. For real research projects, the code would likely be more complicated, and be run multiple times, so the emissions would be much higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4e680",
   "metadata": {},
   "source": [
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e11bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9de041bc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack25_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
