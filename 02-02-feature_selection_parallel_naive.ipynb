{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebe7b40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f9251b0",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c116f8",
   "metadata": {},
   "source": [
    "## Why feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5275fe48",
   "metadata": {},
   "source": [
    "Feature selection, or *variable selection*, is an often used technique in machine learning. It is a process of selecting subset of highly relevant data to benefit modelling in many ways. Such as,\n",
    "\n",
    "- Reduce the complexity, that is, improve the efficiency of training [1].\n",
    "\n",
    "- Improve the prediction accuracy [1,2].\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5907fe4",
   "metadata": {},
   "source": [
    "## Find the top *k* features most correlated to Saleprice (NaÃ¯ve method with Parallel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7307e",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "(House price data train.csv from https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "The data have 1460 rows and 81 columns. The following code will print out the data description in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb6765",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65883b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import psutil\n",
    "import os,gc\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469354da",
   "metadata": {},
   "source": [
    "### Define functions for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3397b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # Memory in MB\n",
    "\n",
    "def compute_correlation(i, X_numeric, y):\n",
    "    \"\"\"Helper function to compute Pearson correlation for a single feature.\"\"\"\n",
    "    valid = (~np.isnan(X_numeric[:, i]) & ~np.isnan(y))\n",
    "    if valid.sum() > 1:\n",
    "        return np.abs(scipy.stats.pearsonr(X_numeric[:, i][valid], y[valid]).statistic)\n",
    "    return 0\n",
    "\n",
    "def parallel_feature_selection(X, y, k=20, n_jobs=2):\n",
    "    \"\"\"\n",
    "    Parallelized feature selection using Pearson correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: DataFrame with features\n",
    "    - y: Target variable (Series or array)\n",
    "    - k: Number of top features to select\n",
    "    - n_jobs: Number of parallel jobs (-1 uses all available cores)\n",
    "    \n",
    "    Returns:\n",
    "    - List of selected feature names\n",
    "    \"\"\"\n",
    "\n",
    "    # Select only numerical columns and fill missing values with median values of the columns\n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    # Convert to numpy array for faster processing\n",
    "    X_numeric_array = X_numeric.to_numpy()\n",
    "    y_array = y.to_numpy() if isinstance(y, pd.Series) else y\n",
    "\n",
    "    # Compute correlations for numerical features only\n",
    "    n_features = X_numeric.shape[1]\n",
    "    correlations = Parallel(n_jobs=n_jobs, backend='threading')(\n",
    "        delayed(compute_correlation)(i, X_numeric_array, y_array) for i in range(n_features)\n",
    "    )\n",
    "\n",
    "    # Convert correlations to numpy array and get top k indices\n",
    "    correlations = np.array(correlations)\n",
    "\n",
    "    top_k_indices = np.argsort(correlations)[-k:]\n",
    "    selected_features = X_numeric.columns[top_k_indices].tolist()\n",
    "    #mem_use_after = get_memory_usage()\n",
    "    #print(f\"Memory after naive selection: {mem_use_after:.2f} MB\")\n",
    "    #print(f\"memory use increased {(mem_use_after - mem_use_before):.2f} MB\" )\n",
    "    return selected_features\n",
    "\n",
    "def load_and_evaluate(file_path, k=20, n_runs = 100, n_jobs=2):\n",
    "    # Initialize lists to store metrics\n",
    "    memory_before_list = []\n",
    "    memory_after_list = []\n",
    "    memory_increase_list = []\n",
    "    runtime_list = []\n",
    "    mse_list = []\n",
    "\n",
    "    #load data\n",
    "    data = pd.read_csv(file_path)\n",
    "    # split Sale price and other columns\n",
    "    X = data.drop(columns=['SalePrice', 'Id'])\n",
    "    y = data['SalePrice']\n",
    "    # Handle missing values for numerical columns \n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    X_categorical = X.select_dtypes(exclude=[np.number])\n",
    "    # Combine numerical and categorical columns\n",
    "    X = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "    \n",
    "    # Verify no NaNs remain \n",
    "    if X.isna().any().any():\n",
    "        X = X.fillna(0)  # Fill any remaining NaNs with 0 (e.g., for edge cases)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Monte Carlo method for testing mem use and runtime\n",
    "    print(f\"Running naive method {n_runs} times...\")\n",
    "    for run in range(n_runs):\n",
    "        # clear memory before each run\n",
    "        gc.collect() \n",
    "        mem_use_before = get_memory_usage()\n",
    "        #print(f\"Memory before naive selection: {mem_use_before:.2f} MB\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+run)\n",
    "        selected_features = parallel_feature_selection(X_train, y_train, k, n_jobs)\n",
    "        X_train_selected = X_train[selected_features]\n",
    "        X_test_selected = X_test[selected_features]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        mem_use_after = get_memory_usage()\n",
    "        end_time = time.time()\n",
    "        # Store metrics\n",
    "        memory_before_list.append(mem_use_before)\n",
    "        memory_after_list.append(mem_use_after)\n",
    "        memory_increase_list.append(mem_use_after - mem_use_before)\n",
    "        runtime_list.append(end_time - start_time)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "    #print(f\"Memory after naive selection: {mem_use_after:.2f} MB\")\n",
    "\n",
    "    #print(f\"Naive feature selection took {time.time() - start_time} seconds\")\n",
    "    \n",
    "    # Ensure selected features are NaN-free\n",
    "    #X_train_selected = X_train[selected_features]\n",
    "    #X_test_selected = X_test[selected_features]\n",
    "    \n",
    "    #model = LinearRegression()\n",
    "    #model.fit(X_train_selected, y_train)\n",
    "    #y_pred = model.predict(X_test_selected)\n",
    "    #mse = mean_squared_error(y_test, y_pred)\n",
    "    #print(f\"Mean Squared Error with {k} features: {mse}\")\n",
    "\n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        'memory_before_mean (MB)': np.mean(memory_before_list),\n",
    "        'memory_before_std': np.std(memory_before_list),\n",
    "        'memory_after_mean (MB)': np.mean(memory_after_list),\n",
    "        'memory_after_std': np.std(memory_after_list),\n",
    "        'memory_increase_mean (MB)': np.mean(memory_increase_list),\n",
    "        'memory_increase_std': np.std(memory_increase_list),\n",
    "        'runtime_mean (Seconds)': np.mean(runtime_list),\n",
    "        'runtime_std': np.std(runtime_list),\n",
    "        'MSE_mean': np.mean(mse_list),\n",
    "        'MSE_std': np.std(mse_list)\n",
    "\n",
    "    }\n",
    "    \n",
    "    return selected_features, mse, stats\n",
    "\n",
    "def generate_report(stats, method=\"Naive\"):\n",
    "    report = f\"# {method} Method Statistical Report\\n\\n\"\n",
    "    report += \"## Summary Statistics\\n\\n\"\n",
    "    report += \"| Metric | Mean | Standard Deviation |\\n\"\n",
    "    report += \"|--------|------|--------------------|\\n\"\n",
    "    report += f\"| Memory Before (MB) | {stats['memory_before_mean (MB)']:.2f} | {stats['memory_before_std']:.2f} |\\n\"\n",
    "    report += f\"| Memory After (MB) | {stats['memory_after_mean (MB)']:.2f} | {stats['memory_after_std']:.2f} |\\n\"\n",
    "    report += f\"| Memory Increase (MB) | {stats['memory_increase_mean (MB)']:.2f} | {stats['memory_increase_std']:.2f} |\\n\"\n",
    "    report += f\"| Runtime (seconds) | {stats['runtime_mean (Seconds)']:.6f} | {stats['runtime_std']:.6f} |\\n\"\n",
    "    report += f\"| MSE | {stats['MSE_mean']:.2f} | {stats['MSE_std']:.2f} |\\n\"\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a36ec3d",
   "metadata": {},
   "source": [
    "### Main process of evaluation with Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87cee4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running naive method 500 times...\n",
      "Naive method report generated: naive_stats_report.md\n",
      "\n",
      "Summary Statistics:\n",
      "memory_before_mean (MB): 188.491328\n",
      "memory_before_std: 6.470636\n",
      "memory_after_mean (MB): 188.565937\n",
      "memory_after_std: 6.373005\n",
      "memory_increase_mean (MB): 0.074609\n",
      "memory_increase_std: 0.242563\n",
      "runtime_mean (Seconds): 0.062643\n",
      "runtime_std: 0.005848\n",
      "MSE_mean: 1495907264.707669\n",
      "MSE_std: 668916768.381671\n",
      "Selected features: ['LotArea', 'HalfBath', '2ndFlrSF', 'WoodDeckSF', 'LotFrontage', 'OpenPorchSF', 'BsmtFinSF1', 'Fireplaces', 'MasVnrArea', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt', 'TotRmsAbvGrd', 'FullBath', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GarageCars', 'GrLivArea', 'OverallQual']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    file_path = \"data/train.csv\"\n",
    "    n_runs = 500\n",
    "    n_jobs=2\n",
    "    selected_features, mse, stats = load_and_evaluate(file_path,  k=20, n_runs=n_runs, n_jobs=n_jobs)\n",
    "    #print(f\"Selected features (last run): {selected_features}\")\n",
    "    report = generate_report(stats, method=\"Naive\")\n",
    "    with open(\"naive_stats_report.md\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(\"Naive method report generated: naive_stats_report.md\")\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.6f}\")\n",
    "    #mem_use_after = get_memory_usage()\n",
    "    #print(f\"Memory after naive selection: {mem_use_after:.2f} MB\")\n",
    "    #print(f\"memory use increased {(mem_use_after - mem_use_before):.2f} MB\" )\n",
    "    print(f\"Selected features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675008e9",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Parallel method with Monte Carlo introduces overhead for \n",
    "\n",
    "- parallelization: process creation and communication\n",
    "\n",
    "- Monte Carlo method introduces cumulative parallelization overhead\n",
    "\n",
    "Therefore, for small tasks like this, parallel method does not necessarily faster than the loop-based single thread job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722a486",
   "metadata": {},
   "source": [
    "### Try with a larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb8ef8",
   "metadata": {},
   "source": [
    "# run this only once\n",
    "def generate_synthetic_dataset(n_rows=100000, n_features=500, file_path=\"synthetic_data.csv\"):\n",
    "    print(f\"Generating synthetic dataset with {n_rows} rows and {n_features} features...\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate numerical features\n",
    "    X = np.random.randn(n_rows, n_features)\n",
    "    print(f\"X shape: {X.shape}\")  # Debug: Confirm 2D shape (n_rows, n_features)\n",
    "    \n",
    "    # Generate target variable with some correlated features\n",
    "    weights = np.random.uniform(0.1, 1.0, 20)  # 20 features with significant correlation\n",
    "    correlated_indices = np.random.choice(n_features, 20, replace=False)\n",
    "    print(f\"Correlated indices: {correlated_indices[:5]}...\")  # Debug: Show first few indices\n",
    "    y = np.zeros(n_rows)\n",
    "    for idx, weight in zip(correlated_indices, weights):\n",
    "        column = X[:, idx]  # Access column\n",
    "        print(f\"Column {idx} shape: {column.shape}\")  # Debug: Confirm 1D shape (n_rows,)\n",
    "        y += weight * column\n",
    "    y += np.random.randn(n_rows) * 0.1  # Add noise\n",
    "    print(f\"y shape: {y.shape}\")  # Debug: Confirm 1D shape (n_rows,)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    columns = [f\"Feature_{i}\" for i in range(n_features)]\n",
    "    data = pd.DataFrame(X, columns=columns)\n",
    "    data[\"SalePrice\"] = y\n",
    "    data[\"Id\"] = range(1, n_rows + 1)\n",
    "    \n",
    "    # Introduce some missing values (5% of numerical data)\n",
    "    mask = np.random.random((n_rows, n_features)) < 0.05\n",
    "    print(f\"Mask shape: {mask.shape}\")  # Debug: Confirm 2D shape (n_rows, n_features)\n",
    "    data.iloc[:, :n_features][mask] = np.nan  # Apply mask to numerical features only\n",
    "    \n",
    "    # Save to CSV\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(f\"Dataset saved to {file_path}\")\n",
    "    return file_path\n",
    "file_path = generate_synthetic_dataset(n_rows=100000, n_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97dbab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running both methods 10 times...\n",
      "# Feature Selection Method Comparison Report\n",
      "\n",
      "## Summary Statistics\n",
      "\n",
      "### Naive Method\n",
      "| Metric | Mean | Standard Deviation |\n",
      "|--------|------|--------------------|\n",
      "| Memory Before (MB) | 1561.66 | 174.43 |\n",
      "| Memory After (MB) | 1487.98 | 205.38 |\n",
      "| Memory Increase (MB) | -73.68 | 273.52 |\n",
      "| Runtime (Seconds) | 5.4579 | 0.1668 |\n",
      "| MSE | 0.01 | 0.00 |\n",
      "\n",
      "### Parallel Method\n",
      "| Metric | Mean | Standard Deviation |\n",
      "|--------|------|--------------------|\n",
      "| Memory Before (MB) | 1488.53 | 204.84 |\n",
      "| Memory After (MB) | 1336.93 | 296.75 |\n",
      "| Memory Increase (MB) | -151.60 | 232.06 |\n",
      "| Runtime (Seconds) | 2.7431 | 2.1951 |\n",
      "| MSE | 0.01 | 0.00 |\n",
      "\n",
      "## Key Comparison\n",
      "- **Runtime Difference (Naive - Parallel)**: 2.7148 seconds\n",
      "  - Positive means parallel is faster; negative means naive is faster.\n",
      "- **MSE Difference (Naive - Parallel)**: 0.00\n",
      "  - Similar MSE values indicate both methods select comparable features.\n",
      "\n",
      "Report saved to comparison_report.md\n"
     ]
    }
   ],
   "source": [
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # Memory in MB\n",
    "\n",
    "def naive_feature_selection(X, y, k=20):\n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    n_features = X_numeric.shape[1]\n",
    "    correlations = np.zeros(n_features)\n",
    "    for i in range(n_features):\n",
    "        valid = (~np.isnan(X_numeric.iloc[:, i]) & ~np.isnan(y))\n",
    "        if valid.sum() > 1:\n",
    "            correlations[i] = np.abs(scipy.stats.pearsonr(X_numeric.iloc[:, i][valid], y[valid]).statistic)\n",
    "        else:\n",
    "            correlations[i] = 0\n",
    "    top_k_indices = np.argsort(correlations)[-k:]\n",
    "    return X_numeric.columns[top_k_indices].tolist()\n",
    "\n",
    "def compute_correlation(i, X_numeric, y):\n",
    "    valid = (~np.isnan(X_numeric[:, i]) & ~np.isnan(y))\n",
    "    if valid.sum() > 1:\n",
    "        return np.abs(scipy.stats.pearsonr(X_numeric[:, i][valid], y[valid]).statistic)\n",
    "    return 0\n",
    "\n",
    "def parallel_feature_selection(X, y, k=20, n_jobs=-1):\n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    X_numeric_array = X_numeric.to_numpy()\n",
    "    y_array = y.to_numpy() if isinstance(y, pd.Series) else y\n",
    "    n_features = X_numeric_array.shape[1]\n",
    "    correlations = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_correlation)(i, X_numeric_array, y_array) for i in range(n_features)\n",
    "    )\n",
    "    correlations = np.array(correlations)\n",
    "    top_k_indices = np.argsort(correlations)[-k:]\n",
    "    return X_numeric.columns[top_k_indices].tolist()\n",
    "\n",
    "\n",
    "def load_and_evaluate(file_path, k=20, n_runs=10, n_jobs=-1):\n",
    "    metrics = {\n",
    "        \"naive\": {\"memory_before\": [], \"memory_after\": [], \"memory_increase\": [], \"runtime\": [], \"mse\": []},\n",
    "        \"parallel\": {\"memory_before\": [], \"memory_after\": [], \"memory_increase\": [], \"runtime\": [], \"mse\": []}\n",
    "    }\n",
    "    \n",
    "    data = pd.read_csv(file_path)\n",
    "    X = data.drop(columns=[\"SalePrice\", \"Id\"])\n",
    "    y = data[\"SalePrice\"]\n",
    "    \n",
    "    X_numeric = X.select_dtypes(include=[np.number]).fillna(X.select_dtypes(include=[np.number]).median())\n",
    "    X_categorical = X.select_dtypes(exclude=[np.number])\n",
    "    X = pd.concat([X_numeric, X_categorical], axis=1)\n",
    "    if X.isna().any().any():\n",
    "        X = X.fillna(0)\n",
    "    \n",
    "    print(f\"Running both methods {n_runs} times...\")\n",
    "    for run in range(n_runs):\n",
    "        gc.collect()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42+run)\n",
    "        \n",
    "        # Naive method\n",
    "        mem_before = get_memory_usage()\n",
    "        start_time = time.time()\n",
    "        selected_features_naive = naive_feature_selection(X_train, y_train, k)\n",
    "        X_train_selected = X_train[selected_features_naive]\n",
    "        X_test_selected = X_test[selected_features_naive]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mem_after = get_memory_usage()\n",
    "        runtime = time.time() - start_time\n",
    "        metrics[\"naive\"][\"memory_before\"].append(mem_before)\n",
    "        metrics[\"naive\"][\"memory_after\"].append(mem_after)\n",
    "        metrics[\"naive\"][\"memory_increase\"].append(mem_after - mem_before)\n",
    "        metrics[\"naive\"][\"runtime\"].append(runtime)\n",
    "        metrics[\"naive\"][\"mse\"].append(mse)\n",
    "        \n",
    "        # Parallel method\n",
    "        gc.collect()\n",
    "        mem_before = get_memory_usage()\n",
    "        start_time = time.time()\n",
    "        selected_features_parallel = parallel_feature_selection(X_train, y_train, k, n_jobs)\n",
    "        X_train_selected = X_train[selected_features_parallel]\n",
    "        X_test_selected = X_test[selected_features_parallel]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mem_after = get_memory_usage()\n",
    "        runtime = time.time() - start_time\n",
    "        metrics[\"parallel\"][\"memory_before\"].append(mem_before)\n",
    "        metrics[\"parallel\"][\"memory_after\"].append(mem_after)\n",
    "        metrics[\"parallel\"][\"memory_increase\"].append(mem_after - mem_before)\n",
    "        metrics[\"parallel\"][\"runtime\"].append(runtime)\n",
    "        metrics[\"parallel\"][\"mse\"].append(mse)\n",
    "    \n",
    "    stats = {}\n",
    "    for method in [\"naive\", \"parallel\"]:\n",
    "        stats[method] = {\n",
    "            \"memory_before_mean (MB)\": np.mean(metrics[method][\"memory_before\"]),\n",
    "            \"memory_before_std\": np.std(metrics[method][\"memory_before\"]),\n",
    "            \"memory_after_mean (MB)\": np.mean(metrics[method][\"memory_after\"]),\n",
    "            \"memory_after_std\": np.std(metrics[method][\"memory_after\"]),\n",
    "            \"memory_increase_mean (MB)\": np.mean(metrics[method][\"memory_increase\"]),\n",
    "            \"memory_increase_std\": np.std(metrics[method][\"memory_increase\"]),\n",
    "            \"runtime_mean (Seconds)\": np.mean(metrics[method][\"runtime\"]),\n",
    "            \"runtime_std\": np.std(metrics[method][\"runtime\"]),\n",
    "            \"MSE_mean\": np.mean(metrics[method][\"mse\"]),\n",
    "            \"MSE_std\": np.std(metrics[method][\"mse\"])\n",
    "        }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def generate_comparison_report(stats):\n",
    "    report = \"# Feature Selection Method Comparison Report\\n\\n\"\n",
    "    report += \"## Summary Statistics\\n\\n\"\n",
    "    for method in [\"naive\", \"parallel\"]:\n",
    "        report += f\"### {method.capitalize()} Method\\n\"\n",
    "        report += \"| Metric | Mean | Standard Deviation |\\n\"\n",
    "        report += \"|--------|------|--------------------|\\n\"\n",
    "        report += f\"| Memory Before (MB) | {stats[method]['memory_before_mean (MB)']:.2f} | {stats[method]['memory_before_std']:.2f} |\\n\"\n",
    "        report += f\"| Memory After (MB) | {stats[method]['memory_after_mean (MB)']:.2f} | {stats[method]['memory_after_std']:.2f} |\\n\"\n",
    "        report += f\"| Memory Increase (MB) | {stats[method]['memory_increase_mean (MB)']:.2f} | {stats[method]['memory_increase_std']:.2f} |\\n\"\n",
    "        report += f\"| Runtime (Seconds) | {stats[method]['runtime_mean (Seconds)']:.4f} | {stats[method]['runtime_std']:.4f} |\\n\"\n",
    "        report += f\"| MSE | {stats[method]['MSE_mean']:.2f} | {stats[method]['MSE_std']:.2f} |\\n\\n\"\n",
    "    \n",
    "    runtime_diff = stats[\"naive\"][\"runtime_mean (Seconds)\"] - stats[\"parallel\"][\"runtime_mean (Seconds)\"]\n",
    "    report += \"## Key Comparison\\n\"\n",
    "    report += f\"- **Runtime Difference (Naive - Parallel)**: {runtime_diff:.4f} seconds\\n\"\n",
    "    report += f\"  - Positive means parallel is faster; negative means naive is faster.\\n\"\n",
    "    report += f\"- **MSE Difference (Naive - Parallel)**: {stats['naive']['MSE_mean'] - stats['parallel']['MSE_mean']:.2f}\\n\"\n",
    "    report += f\"  - Similar MSE values indicate both methods select comparable features.\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        file_path = \"data/synthetic_data.csv\"\n",
    "        stats = load_and_evaluate(file_path, k=20, n_runs=10, n_jobs=-1)\n",
    "        report = generate_comparison_report(stats)\n",
    "        print(report)\n",
    "        with open(\"comparison_report.md\", \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(\"Report saved to comparison_report.md\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806df5c",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). \"An Introduction to Statistical Learning\". *Springer*. p. 204.\n",
    "2. Kratsios, Anastasis; Hyndman, Cody (2021). \"NEU: A Meta-Algorithm for Universal UAP-Invariant Feature Representation\". *Journal of Machine Learning Research*. 22 (92): 1â51"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
